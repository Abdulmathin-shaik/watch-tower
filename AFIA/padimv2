#!/usr/bin/env python3
"""
padim.py

A simplified PyTorch implementation of PaDiM-style anomaly detection, 
with “anomaly vs. normal” decision logic at inference.

Usage:
    python padim.py train      # computes mean, cov, and threshold from data/train/normal
    python padim.py infer      # runs inference on data/test/*.png, prints Normal/ANOMALY

Dependencies:
    torch, torchvision, numpy, pillow, opencv-python
"""

import os
import argparse
import glob
import json
import numpy as np
from PIL import Image
import cv2
import torch
import torch.nn as nn
import torchvision.transforms as T
import torchvision.models as models


# -----------------------------------------------------------------------------
# 1) Utility: FeatureExtractor to hook a given ResNet layer
# -----------------------------------------------------------------------------
class FeatureExtractor(nn.Module):
    def __init__(self, layer_name: str = "layer2"):
        super().__init__()
        # Load pre-trained ResNet-18 and extract layers up to the one we want.
        resnet = models.resnet18(pretrained=True)
        resnet.eval()

        # Keep only layers up to "layer_name"
        self.features = nn.Sequential()
        for name, module in resnet.named_children():
            if name == "fc":
                break
            self.features.add_module(name, module)
            if name == layer_name:
                break

        # Register forward hook to capture the output of the specified layer
        self._hook_output = None
        target_module = dict(self.features.named_modules())[layer_name]
        target_module.register_forward_hook(self._hook_fn)

    def _hook_fn(self, module, input, output):
        # When forward is called, this hook saves the output of layer_name
        self._hook_output = output

    def forward(self, x: torch.Tensor):
        _ = self.features(x)
        return self._hook_output  # [B, C, H, W]


# -----------------------------------------------------------------------------
# 2) PaDiM Trainer / Inference Logic
# -----------------------------------------------------------------------------
class PaDiM:
    def __init__(self, layer: str = "layer2", device: str = "cpu"):
        """
        layer: which ResNet layer to extract (e.g. 'layer1', 'layer2', 'layer3')
        device: 'cpu' or 'cuda'
        """
        self.device = device
        self.extractor = FeatureExtractor(layer_name=layer).to(self.device)
        self.mean = None              # [C]
        self.cov_inv = None           # [C, C]
        self.threshold = None         # scalar threshold for anomaly decision
        self.patch_shape = None       # (H, W) of feature map
        self.feature_dim = None       # C
        self.eps = 1e-6               # for numerical stability in covariance

    def _load_image(self, path: str):
        """
        Load an image from disk, convert to RGB, apply transforms.
        Returns a torch.Tensor [1, 3, 224, 224].
        """
        img = Image.open(path).convert("RGB")
        transform = T.Compose([
            T.Resize((224, 224)),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406],
                        [0.229, 0.224, 0.225]),
        ])
        return transform(img).unsqueeze(0).to(self.device)  # [1,3,224,224]

    def fit(self, normal_dir: str):
        """
        1) Iterate over all normal images, extract patch embeddings from chosen layer.
        2) Flatten all patches into a big [M, C] array.
        3) Compute mean [C] and covariance [C, C], store inverse covariance.
        4) Compute Mahalanobis distances on these patches to pick a threshold.
        """
        print(f"[PaDiM] Training on normal images in: {normal_dir}")
        feat_list = []

        with torch.no_grad():
            for img_path in sorted(glob.glob(os.path.join(normal_dir, "*"))):
                img_tensor = self._load_image(img_path)           # [1,3,224,224]
                feats = self.extractor(img_tensor)                 # [1, C, H, W]
                feats = feats.squeeze(0)                           # [C, H, W]
                C, H, W = feats.shape
                if self.feature_dim is None:
                    self.feature_dim = C
                    self.patch_shape = (H, W)
                # Reshape to [H*W, C]
                patches = feats.permute(1, 2, 0).reshape(-1, C)     # [H*W, C]
                feat_list.append(patches.cpu().numpy())

        # Stack all patch embeddings: [M, C]
        all_patches = np.vstack(feat_list)                        # [M, C]
        print(f"[PaDiM] Total patches collected: {all_patches.shape[0]} (dim={self.feature_dim})")

        # Compute mean [C] and covariance [C, C]
        self.mean = np.mean(all_patches, axis=0)                   # [C]
        cov = np.cov(all_patches, rowvar=False)                    # [C, C]
        cov += np.eye(self.feature_dim) * self.eps                  # regularize
        self.cov_inv = np.linalg.inv(cov)                           # [C, C]

        # Compute Mahalanobis distances on training patches to pick threshold
        print("[PaDiM] Computing Mahalanobis distances on training patches for thresholding...")
        diff = all_patches - self.mean                              # [M, C]
        left = diff.dot(self.cov_inv)                                # [M, C]
        d2 = np.sum(left * diff, axis=1)                             # [M]
        dists_train = np.sqrt(d2 + 1e-8)                             # [M]

        # Choose threshold = 95th percentile of train distances
        self.threshold = np.percentile(dists_train, 95)
        print(f"[PaDiM] 95th percentile distance = {self.threshold:.4f}")

        # Save statistics (mean, cov_inv, patch_shape, feature_dim, threshold)
        stats = {
            "mean": self.mean.tolist(),
            "cov_inv": self.cov_inv.tolist(),
            "feature_dim": self.feature_dim,
            "patch_shape": self.patch_shape,
            "threshold": float(self.threshold)
        }
        with open("padim_stats.json", "w") as f:
            json.dump(stats, f)
        print("[PaDiM] Training complete. Stats saved to padim_stats.json.")

    def load_stats(self, stats_path: str = "padim_stats.json"):
        """
        Load precomputed mean, inverse covariance, and threshold from disk.
        """
        with open(stats_path, "r") as f:
            stats = json.load(f)
        self.mean = np.array(stats["mean"])
        self.cov_inv = np.array(stats["cov_inv"])
        self.feature_dim = stats["feature_dim"]
        self.patch_shape = tuple(stats["patch_shape"])
        self.threshold = stats.get("threshold", None)
        print(f"[PaDiM] Loaded stats (threshold = {self.threshold:.4f})")

    def _mahalanobis(self, patches: np.ndarray) -> np.ndarray:
        """
        Compute Mahalanobis distance for each patch embedding.
        patches: [H*W, C]
        Returns distances: [H*W]
        """
        diff = patches - self.mean                                # [H*W, C]
        left = diff.dot(self.cov_inv)                              # [H*W, C]
        dist2 = np.sum(left * diff, axis=1)                        # [H*W]
        return np.sqrt(dist2 + 1e-8)                                # [H*W]

    def predict(self, img_path: str, visualize: bool = True):
        """
        1) Load and preprocess test image
        2) Extract features [1, C, H, W] -> [C, H, W]
        3) Reshape to [H*W, C], compute Mahalanobis distances
        4) Compute image-level anomaly score and compare to threshold
        5) Return (anomaly_score, is_anomaly, heatmap_color, overlay)
        """
        img_tensor = self._load_image(img_path)                     # [1,3,224,224]
        with torch.no_grad():
            feats = self.extractor(img_tensor).squeeze(0)           # [C, H, W]
        C, H, W = feats.shape
        patches = feats.permute(1, 2, 0).reshape(-1, C).cpu().numpy()  # [H*W, C]

        # Compute per-patch distances
        dists = self._mahalanobis(patches)                           # [H*W]
        dists_map = dists.reshape(H, W)                              # [H, W]

        # Image-level anomaly score: mean of top 1% patch distances
        num_top = max(1, int(0.01 * H * W))
        anomaly_score = np.mean(np.sort(dists)[-num_top:])

        # Determine if anomaly based on threshold
        is_anomaly = False
        if self.threshold is not None:
            is_anomaly = anomaly_score > self.threshold

        # Normalize & upsample for visualization
        dists_norm = (dists_map - dists_map.min()) / (dists_map.max() - dists_map.min() + 1e-8)
        heatmap = cv2.resize(dists_norm.astype(np.float32), (224, 224))
        heatmap = (heatmap * 255).astype(np.uint8)
        heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

        # Overlay on original image
        orig = np.array(Image.open(img_path).convert("RGB").resize((224, 224)))
        overlay = cv2.addWeighted(orig, 0.6, heatmap_color, 0.4, 0)

        if visualize:
            label = "ANOMALY" if is_anomaly else "Normal"
            color = (0, 0, 255) if is_anomaly else (0, 255, 0)
            cv2.putText(overlay, label, (5, 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            cv2.imshow("Input Image", orig)
            cv2.imshow("Anomaly Heatmap", heatmap_color)
            cv2.imshow("Overlay", overlay)
            print(f"[PaDiM] {os.path.basename(img_path)}: score = {anomaly_score:.4f} --> {label}")
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        return anomaly_score, is_anomaly, heatmap_color, overlay


# -----------------------------------------------------------------------------
# 3) Main: train or infer based on CLI argument
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Simplified PaDiM Implementation")
    subparsers = parser.add_subparsers(dest="command")

    # Train subcommand
    parser_train = subparsers.add_parser("train", help="Compute mean, cov, and threshold from normal images")
    parser_train.add_argument("--train_dir", type=str, default="data/train/normal",
                              help="Folder containing 'normal' training images")

    # Infer subcommand
    parser_infer = subparsers.add_parser("infer", help="Run inference on all test images")
    parser_infer.add_argument("--test_dir", type=str, default="data/test",
                              help="Folder containing test images")
    parser_infer.add_argument("--stats", type=str, default="padim_stats.json",
                              help="Path to saved padim_stats.json")

    args = parser.parse_args()

    device = "cuda" if torch.cuda.is_available() else "cpu"
    detector = PaDiM(layer="layer2", device=device)

    if args.command == "train":
        detector.fit(normal_dir=args.train_dir)

    elif args.command == "infer":
        detector.load_stats(stats_path=args.stats)
        for img_path in sorted(glob.glob(os.path.join(args.test_dir, "*"))):
            _ = detector.predict(img_path, visualize=False)
            # The predict() call already prints “ANOMALY” or “Normal” with the score.
    else:
        parser.print_help()