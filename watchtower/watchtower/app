from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from PIL import Image
import io
import cv2
import numpy as np
import pytesseract

app = Flask(__name__)
CORS(app)

# Load models
# Object Detection (Faster R-CNN with ResNet50 backbone, pretrained on COCO)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
detection_model = fasterrcnn_resnet50_fpn(pretrained=True)
detection_model.eval()
detection_model.to(device)

# COCO class names (91 classes, but we'll use the 80 main ones + background)
COCO_CLASSES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',
    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',
    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',
    'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',
    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# Image Classification (ResNet50)
classify_model = models.resnet50(pretrained=True)
classify_model.eval()
classify_model.to(device)
with open('imagenet_classes.txt', 'r') as f:  # ImageNet class names file needed
    imagenet_classes = [line.strip() for line in f.readlines()]

# Preprocessing for classification
preprocess_classify = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Preprocessing for detection (Faster R-CNN expects a tensor)
preprocess_detect = transforms.Compose([
    transforms.ToTensor(),
])

@app.route('/api/inspect', methods=['POST'])
def inspect():
    if 'image' not in request.files:
        return jsonify({'result': 'No image uploaded.'}), 400

    image_file = request.files['image']
    inspection_type = request.form['type']
    image = Image.open(io.BytesIO(image_file.read())).convert('RGB')
    img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

    if inspection_type == 'object':
        # Object Detection with Faster R-CNN
        img_tensor = preprocess_detect(image).to(device)
        with torch.no_grad():
            predictions = detection_model([img_tensor])[0]
        
        labels = predictions['labels'].cpu().numpy()
        scores = predictions['scores'].cpu().numpy()
        boxes = predictions['boxes'].cpu().numpy()

        # Filter detections with confidence > 0.5
        threshold = 0.5
        detections = [(COCO_CLASSES[label], score) for label, score in zip(labels, scores) if score > threshold]
        
        if detections:
            output = f"Detected {len(detections)} objects: "
            output += ", ".join([f"{name} ({score:.2f})" for name, score in detections])
        else:
            output = "No objects detected above threshold."
        return jsonify({'result': output})

    elif inspection_type == 'classify':
        # Image Classification with ResNet50
        input_tensor = preprocess_classify(image).unsqueeze(0).to(device)
        with torch.no_grad():
            output = classify_model(input_tensor)
            probabilities = torch.nn.functional.softmax(output[0], dim=0)
            top_prob, top_idx = probabilities.topk(1)
            label = imagenet_classes[top_idx[0]]
            confidence = top_prob[0].item()
        return jsonify({'result': f"Classified as '{label}' with {confidence:.2%} confidence."})

    elif inspection_type == 'anomaly':
        # Anomaly Detection (simple thresholding example)
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        anomalies = cv2.countNonZero(thresh)
        if anomalies > 1000:  # Arbitrary threshold
            output = "Anomaly detected: Significant deviations found."
        else:
            output = "No significant anomalies detected."
        return jsonify({'result': output})

    elif inspection_type == 'ocr':
        # OCR with Tesseract
        text = pytesseract.image_to_string(img_cv)
        if text.strip():
            output = f"Extracted text: '{text.strip()}'"
        else:
            output = "No text detected."
        return jsonify({'result': output})

    return jsonify({'result': 'Invalid inspection type.'}), 400

if __name__ == '__main__':
    app.run(debug=True, port=5000)